{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code by Nick Kolkin (Modified by Davis Yoshida for use on MNIST)\n",
    "\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# some utilities\n",
    "class_names = list(map(str, range(10)))\n",
    "\n",
    "def create_submission_file(fname, preds):\n",
    "    \"\"\"\n",
    "    Create Kaggle submision with predictions written as a csv (comma separated values) file \n",
    "    \"\"\"\n",
    "    \n",
    "    ofile  = open(fname, \"w\")\n",
    "    writer = csv.writer(ofile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)    \n",
    "    \n",
    "    writer.writerow(['id', 'category'])\n",
    "    \n",
    "    \n",
    "    for i in range(preds.shape[0]):\n",
    "        writer.writerow([i,preds[i]])\n",
    "        \n",
    "\n",
    "        \n",
    "def read_MNIST(dataset = \"training\", path = \"data\", load_small=False):\n",
    "    \"\"\"\n",
    "    reading in the \"MNIST\" data\n",
    "    this function allows specification of the part to be read (training/testing/validation)\n",
    "    if load_small = True, this will look for the file(s) associated with the small training set\n",
    "    Note that if dataset='testing', no labels will be returned\n",
    "    \"\"\"\n",
    "    \n",
    "    #Figure out the name of the file to load    \n",
    "    if dataset.lower() == \"training\":\n",
    "        file_name_suffix = 'Tr'\n",
    "        has_labels = True\n",
    "    \n",
    "    elif dataset.lower() == \"validation\":\n",
    "        file_name_suffix = 'Vl'\n",
    "        has_labels = True\n",
    "\n",
    "    elif dataset.lower() == \"testing\":\n",
    "        file_name_suffix = 'Te'\n",
    "        has_labels = False\n",
    "\n",
    "    else:\n",
    "        print(\"dataset must be 'testing','validation', or 'training'\")\n",
    "        raise ValueError\n",
    "    \n",
    "    if load_small:\n",
    "        file_name_suffix += '_sm'\n",
    "    \n",
    "    #Load the appropriate files\n",
    "    X = np.load(path + '/x'+file_name_suffix+'.npy')\n",
    "    if has_labels:\n",
    "        y = np.load(path + '/y'+file_name_suffix+'.npy')\n",
    "    \n",
    "\n",
    "    #Return the appropriate data\n",
    "    if has_labels:\n",
    "        return X,y\n",
    "    else:\n",
    "        return X\n",
    "         \n",
    "            \n",
    "def show_MNIST_example(image):\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 2D array of pixel data.\n",
    "    \"\"\"\n",
    "    image = image[-28**2:]\n",
    "    image = image.reshape(28,28)\n",
    "\n",
    "    fig = pyplot.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    pyplot.axis('off')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build the code for our softmax model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(scores):\n",
    "    \"\"\"\n",
    "    takes the softmax along the second dimension of a matrix, returns class scores\n",
    "    \"\"\"\n",
    "    # we will adjust the dynamic range by subtracting the max, to prevent potential underflow in exp\n",
    "    exp_scores = np.exp(scores-np.max(scores,axis=1,keepdims=True))+1e-6\n",
    "    return exp_scores/(np.sum(exp_scores,axis=1,keepdims=True))\n",
    "\n",
    "\n",
    "def log_likelihood(X,w,y):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "      X: a Nxd matrix where each of the N rows is a datapoint with d features\n",
    "      Y: a Nx10 matrix, each row is a one-hot vector where the ith entry is 1 if that datapoint belongs to class i \n",
    "      w: is a dxC matrix containing your model parameters\n",
    "    Outputs:\n",
    "      LL: a scalar containing the AVERAGE log-likelihood of the dataset's labels y, given inputs X and model w\n",
    "    \"\"\"\n",
    "    #compute the un-normalized 'scores' of each class for each datapoint\n",
    "    scores = np.dot(X,w)\n",
    "    \n",
    "    #normalize the scores to get a distribution over classes for each datapoint\n",
    "    predictions = # Add your code here\n",
    "        \n",
    "    #use the predicted distributions and the true distributions to compute log-likelihood\n",
    "    LL = # Add your code here\n",
    "\n",
    "    return LL\n",
    "\n",
    "def objective(X,w,y):\n",
    "    \"\"\"\n",
    "    Compute components of the optimization objective\n",
    "    Output:\n",
    "    logloss : value of log-loss (negative average log-likelihood)\n",
    "    regularizer: value of the regularization term (Frobenius norm of w), NOT multiplied by lambda\n",
    "    \"\"\"\n",
    "    regularizer = np.linalg.norm(w,'fro')\n",
    "    logloss = - log_likelihood(X,w,y)\n",
    "    return logloss, regularizer\n",
    "\n",
    "\n",
    "def gradient(X,w,y):\n",
    "    \"\"\"\n",
    "    Compute in grad the gradient of the log-loss of the model (w) given the features (X) and labels (y) w.r.t. w\n",
    "    Also compute and return in l2grad the gradient of the regularizer lambda*norm(w)\n",
    "    Note: we can't use the name 'lambda' since it's a keyword in Python\n",
    "    Reminder: the full objective is -log p(y|X;w) + lmbda*norm2(w)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute any extra variable needed to compute the gradient:\n",
    "    scores = np.dot(X,w)\n",
    "    predictions = softmax(scores)\n",
    "\n",
    "    # Compute the gradient of the average log-loss\n",
    "    grad = # Add your code here\n",
    "    \n",
    "    # Compute the gradient of the regularization term\n",
    "    l2grad = # Add your code here\n",
    "    \n",
    "    return grad, l2grad\n",
    "\n",
    "\n",
    "def accuracy(X,w,y):\n",
    "    \"\"\"\n",
    "    Compute accuracy (one minus average 0/1 loss) of model w relative to true labels y on data X\n",
    "    \"\"\"\n",
    "    y_hat = np.argmax(infer(X,w),axis=1)\n",
    "    y = np.argmax(y,axis=1)\n",
    "    acc = np.sum(np.equal(y,y_hat).astype(np.float32))/y.shape[0]\n",
    "    return acc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the SGD (stochastic gradient descent) procedure for softmax, with optional regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_sgd(xTr, yTr, xVl, yVl, lmbda=0, lr = .01,maxepochs=10,bsize=32,objTol=.01,verbose=1):\n",
    "    # initialization of w (feel free to play with this)\n",
    "    w = np.zeros((xTr.shape[1],yTr.shape[1]))\n",
    "    \n",
    "    old_obj = 1e9  \n",
    "    old_w = w\n",
    "    \n",
    "    # we will organize the run in terms of epochs (one epoch = one full pass over data)\n",
    "    # to keep track of learning curves, allocate space\n",
    "    trAcc = np.zeros(maxepochs)\n",
    "    obj = np.zeros(maxepochs)\n",
    "    \n",
    "    for epoch in range(maxepochs):\n",
    "        \n",
    "        #shuffle the data\n",
    "        index = np.random.permutation(xTr.shape[0])\n",
    "        batch_starts = range(0, xTr.shape[0], bsize) # ignore the remainder N-floor(N/bsize), for simplicity\n",
    "    \n",
    "        for start_index in batch_starts:\n",
    "            # fill in the batch\n",
    "            iBatch = index[start_index:start_index + bsize]\n",
    "            xBatch = xTr[iBatch]\n",
    "            yBatch = yTr[iBatch]\n",
    "            \n",
    "            grad,l2grad = gradient(xBatch,w,yBatch)\n",
    "    \n",
    "            w = w-lr*(grad+lmbda*l2grad)\n",
    "            \n",
    "        \n",
    "        # end of an epoch: test for convergence by looking at validation\n",
    "        logloss, regularizer = objective(xTr,w,yTr)\n",
    "        obj[epoch] = logloss+lmbda*regularizer\n",
    "        # also record accuracy on training\n",
    "        trAcc[epoch] = accuracy(xTr,w,yTr)\n",
    "\n",
    "        obj_gain = (old_obj-obj[epoch])/np.abs(old_obj) # improvement in training objective this epoch\n",
    "        \n",
    "        if verbose > 0.5:\n",
    "            print('Epoch %d: obj=%.4f, gain %.4f  [train acc %.4f]'%(epoch,obj[epoch],obj_gain,trAcc[epoch]))\n",
    "        \n",
    "        \n",
    "        if epoch == maxepochs-1:\n",
    "            if verbose > 0:\n",
    "                print('Reached max epochs, stopping')\n",
    "            return w, obj, trAcc\n",
    "        \n",
    "        if obj_gain < objTol:  \n",
    "            lr = lr/2\n",
    "            if verbose > 0:\n",
    "                print('Dropping learning rate to %.4f'%lr)\n",
    "        \n",
    "        # update bookkeeping before going to next epoch\n",
    "        old_obj = obj[epoch]    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start experiments, we need one more piece: feature transform. In this case we are using the \"raw\" features (pixel values) plus the constant term, but with normalization that applies z-scoring to each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if mu and sigma are provided, they are used to normalize each pixel\n",
    "# otherwise, they are computed and returned\n",
    "def preprocess_data(X,mu = None,sigma = None,visualize=False):\n",
    "\n",
    "    if visualize:\n",
    "        print('VISUALIZE BEFORE NORMALIZATION')\n",
    "        #Visualize example before normalization\n",
    "        show_MNIST_example(X[300])\n",
    "        show_MNIST_example(X[500])\n",
    "    \n",
    "    if mu is None: # need to compute normalizing stats\n",
    "        compute_stats = True\n",
    "        mu = X.mean(axis=0, keepdims=True)\n",
    "        sigma = X.std(axis=0, keepdims=True)\n",
    "        sigma[np.equal(sigma,0)]=1.0 # avoid division by zero in case of degenerate features\n",
    "    else:\n",
    "        compute_stats = False\n",
    "        \n",
    "    #Normalize the data\n",
    "    X = (X-mu)/sigma\n",
    "    bias_feature = np.ones((X.shape[0],1))\n",
    "    X = np.concatenate([np.ones((X.shape[0],1)),X],1)\n",
    "\n",
    "    if visualize:\n",
    "        print('VISUALIZE AFTER NORMALIZATION')\n",
    "        #Visualize example after normalization\n",
    "        show_MNIST_example(X[300])\n",
    "        show_MNIST_example(X[500])\n",
    "    \n",
    "    if compute_stats:\n",
    "        return X, mu, sigma\n",
    "    else:\n",
    "        return X\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTr, yTr = read_MNIST('Training')\n",
    "print('Training images')\n",
    "print(str(np.min(xTr[1]))+' ... '+str(np.max(xTr[1])))\n",
    "\n",
    "xTr, mu, sigma = preprocess_data(xTr,visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the main routine for our experiments: load training/validation data sets, and tune the regularization parameter (and perhaps other parameters you want to tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run minibatch SGD for every value of lambda and record training/val accuracy\n",
    "def tune_regularization(xTr,yTr,xVl,yVl,lambdas,sgd_opt):\n",
    "    \n",
    "    obj=dict()\n",
    "    trAcc=dict()\n",
    "    model=dict()\n",
    "    valAcc=dict()\n",
    "\n",
    "    for lmbda in lambdas:\n",
    "        model[lmbda], obj[lmbda],trAcc[lmbda] = minibatch_sgd(xTr,yTr,xVl,yVl,lmbda, sgd_opt['lr'],sgd_opt['maxepochs'],sgd_opt['bsize'],verbose=sgd_opt['verbose'])\n",
    "        valAcc[lmbda] = accuracy(xVl,model[lmbda],yVl)\n",
    "        if sgd_opt['verbose'] >= 0:\n",
    "            print('-------------- lambda=%.5f, val Acc = %.4f  (tr Acc = %.4f)'%(lmbda,valAcc[lmbda],trAcc[lmbda][-1]))\n",
    "        \n",
    "    return model, obj, trAcc, valAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTr, yTr = read_MNIST('Training')\n",
    "xVl, yVl = read_MNIST('Validation')\n",
    "\n",
    "xTr,mu,sigma = preprocess_data(xTr,visualize=False)\n",
    "xVl = preprocess_data(xVl,mu,sigma,visualize=False)\n",
    "\n",
    "lambdas = [0, 1e-5, 1e-4, 1e-2, 1.0, 10.0]\n",
    "\n",
    "sgd_opt = {'bsize':16, 'maxepochs':60, 'lr':.1,'verbose':0}\n",
    "\n",
    "model, obj, trAcc, valAcc = tune_regularization(xTr,yTr,xVl,yVl,lambdas,sgd_opt)\n",
    "\n",
    "# Add your code to select the best model here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the weights of the best model for the Large dataset\n",
    "\n",
    "w=model[best]\n",
    "\n",
    "ind = 0\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "for cn in class_names:\n",
    "    plt.subplot(2,5,ind+1)\n",
    "    plt.imshow(w[-28**2:, ind].reshape(28, 28))\n",
    "    plt.title(\"Weights Viz: \"+cn)\n",
    "    plt.colorbar()\n",
    "    ind += 1\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter, MaxNLocator\n",
    "\n",
    "#Get the names for the tickmarks of the confusion matrix\n",
    "def format_fn(tick_val, tick_pos):\n",
    "    if int(tick_val) in range(10):\n",
    "        return class_names[int(tick_val)]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def build_confusion_matrix(y_hat,y):\n",
    "    conf_mat = np.zeros((10,10))\n",
    "    \n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            #Put the number of datapoints that had class i, and predicted class j in that entry of conf matrix\n",
    "            conf_mat[i,j] = np.sum(np.equal(y,i).astype(np.float32)*np.equal(y_hat,j).astype(np.float32))\n",
    "    \n",
    "    for i in range(10):\n",
    "        #normalize all the rows to sum to 1\n",
    "        conf_mat[i,:] = conf_mat[i,:]/np.sum(conf_mat[i,:])\n",
    "    \n",
    "    #Make plot and add tick for each class\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks(range(10))\n",
    "\n",
    "    #add labels and display matrix\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(format_fn))\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(format_fn))\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    ax.imshow(conf_mat)\n",
    "    plt.show()\n",
    "    \n",
    "    return conf_mat\n",
    "\n",
    "#Visualize Confusion Matrix for best model\n",
    "yVl_pred = np.argmax(infer(xVl,model[best]),axis=1)\n",
    "conv_mat = build_confusion_matrix(yVl_pred,np.argmax(yVl,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe about the visualized weights for each class label?\n",
    "\n",
    "What do you observe in the confusion matrix? \n",
    "\n",
    "What is the impact of regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best model and use it to generate predictions for test data (to be submitted to Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTe = read_MNIST('testing')\n",
    "xTe = preprocess_data(xTe,mu,sigma,visualize=False)\n",
    "\n",
    "\n",
    "#Decide which model you want to use for your submission\n",
    "chosen_model = model[best]\n",
    "\n",
    "#Make predictions and write them to a csv file\n",
    "final_preds = np.argmax(infer(xTe,chosen_model),axis=1)\n",
    "create_submission_file('./large_submission.csv', final_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will repeat this experiment with the small training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTr, yTr = read_MNIST('Training', load_small=True)\n",
    "xVl, yVl = read_MNIST('Validation')\n",
    "xTr,mu,sigma = preprocess_data(xTr,visualize=False)\n",
    "xVl = preprocess_data(xVl,mu,sigma,visualize=False)\n",
    "\n",
    "lambdas = [0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1.0, 10.0]\n",
    "\n",
    "sgd_opt = {'bsize':3, 'maxepochs': 100, 'lr':.1,'verbose':0}\n",
    "\n",
    "model, obj, trAcc, valAcc = tune_regularization(xTr,yTr,xVl,yVl,lambdas,sgd_opt)\n",
    "\n",
    "# Add your code to select the best model for the small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visualize the weights of the best model for the small dataset\n",
    "\n",
    "w=model[best]\n",
    "\n",
    "ind = 0\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "for cn in class_names:\n",
    "    plt.subplot(2,5,ind+1)\n",
    "    plt.imshow(w[-28**2:, ind].reshape(28, 28))\n",
    "    plt.title(\"Weights Viz: \"+cn)\n",
    "    plt.colorbar()\n",
    "    ind += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Confusion Matrix for best model for small dataset\n",
    "yVl_pred = np.argmax(infer(xVl,model[best]),axis=1)\n",
    "conv_mat = build_confusion_matrix(yVl_pred,np.argmax(yVl,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe about the weight visualization and confusion matrix compared to the large training data setting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTe = read_MNIST('testing')\n",
    "xTe = preprocess_data(xTe,mu,sigma,visualize=False)\n",
    "\n",
    "\n",
    "#Decide which model you want to use for your submission\n",
    "chosen_model = model[best]\n",
    "\n",
    "#Make predictions and write them to a csv file\n",
    "final_preds = np.argmax(infer(xTe,chosen_model),axis=1)\n",
    "create_submission_file('./small_submission.csv', final_preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
